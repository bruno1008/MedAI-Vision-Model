{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iC3chFUVYvea"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM, Dot, Reshape, Concatenate, BatchNormalization, GlobalMaxPooling2D, Dropout, Add, MaxPooling2D, GRU, AveragePooling2D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "chexnet_weights = \"brucechou1983_CheXNet_Keras_0.3.0_weights.h5\"\n",
        "\n",
        "# Model Architecture\n",
        "def create_chexnet(chexnet_weights=chexnet_weights, input_size=(224,224)):\n",
        "    model = tf.keras.applications.DenseNet121(include_top=False, input_shape=input_size+(3,))\n",
        "    x = model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(14, activation=\"sigmoid\", name=\"chexnet_output\")(x)\n",
        "    chexnet = tf.keras.Model(inputs=model.input, outputs=x)\n",
        "    chexnet.load_weights(chexnet_weights)\n",
        "    chexnet = tf.keras.Model(inputs=model.input, outputs=chexnet.layers[-3].output)\n",
        "    return chexnet\n",
        "\n",
        "class ImageEncoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, name=\"image_encoder_block\"):\n",
        "        super().__init__()\n",
        "        self.chexnet = create_chexnet(input_size=(224,224))\n",
        "        self.chexnet.trainable = False\n",
        "        self.avgpool = AveragePooling2D(pool_size=(2, 2))\n",
        "\n",
        "    def call(self, data):\n",
        "        op = self.chexnet(data)\n",
        "        op = self.avgpool(op)\n",
        "        op = tf.reshape(op, shape=(-1, op.shape[1]*op.shape[2], op.shape[3]))\n",
        "        return op\n",
        "\n",
        "def encoder(image1, image2, dense_dim, dropout_rate):\n",
        "    im_encoder = ImageEncoder()\n",
        "    bkfeat1 = im_encoder(image1)\n",
        "    bkfeat2 = im_encoder(image2)\n",
        "    bk_dense = Dense(dense_dim, name='bkdense', activation='relu')\n",
        "    bkfeat1 = bk_dense(bkfeat1)\n",
        "    bkfeat2 = bk_dense(bkfeat2)\n",
        "    concat = Concatenate(axis=1)([bkfeat1, bkfeat2])\n",
        "    bn = BatchNormalization(name=\"encoder_batch_norm\")(concat)\n",
        "    dropout = Dropout(dropout_rate, name=\"encoder_dropout\")(bn)\n",
        "    return dropout\n",
        "\n",
        "class GlobalAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, dense_dim):\n",
        "        super().__init__()\n",
        "        self.W1 = Dense(units=dense_dim)\n",
        "        self.W2 = Dense(units=dense_dim)\n",
        "        self.V = Dense(units=1)\n",
        "\n",
        "    def call(self, encoder_output, decoder_h):\n",
        "        decoder_h = tf.expand_dims(decoder_h, axis=1)\n",
        "        tanh_input = self.W1(encoder_output) + self.W2(decoder_h)\n",
        "        tanh_output = tf.nn.tanh(tanh_input)\n",
        "        attention_weights = tf.nn.softmax(self.V(tanh_output), axis=1)\n",
        "        context_vector = tf.reduce_sum(attention_weights * encoder_output, axis=1)\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "class OneStepDecoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, vocab_size, embedding_dim, max_pad, dense_dim, name=\"onestepdecoder\"):\n",
        "        super().__init__()\n",
        "        self.dense_dim = dense_dim\n",
        "        self.embedding = Embedding(input_dim=vocab_size+1, output_dim=embedding_dim, input_length=max_pad, mask_zero=True, name='onestepdecoder_embedding')\n",
        "        self.LSTM = GRU(units=self.dense_dim, return_state=True, name='onestepdecoder_LSTM')\n",
        "        self.attention = GlobalAttention(dense_dim=dense_dim)\n",
        "        self.dense = Dense(dense_dim, name='onestepdecoder_embedding_dense', activation='relu')\n",
        "        self.final = Dense(vocab_size+1, activation='softmax')\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, input_to_decoder, encoder_output, decoder_h):\n",
        "        embedding_op = self.embedding(input_to_decoder)\n",
        "        context_vector, attention_weights = self.attention(encoder_output, decoder_h)\n",
        "        context_vector_time_axis = tf.expand_dims(context_vector, axis=1)\n",
        "        concat_input = Concatenate(axis=-1)([context_vector_time_axis, embedding_op])\n",
        "        output, decoder_h = self.LSTM(concat_input, initial_state=decoder_h)\n",
        "        output = self.final(output)\n",
        "        return output, decoder_h, attention_weights\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, max_pad, embedding_dim, dense_dim, batch_size, vocab_size):\n",
        "        super().__init__()\n",
        "        self.onestepdecoder = OneStepDecoder(vocab_size=vocab_size, embedding_dim=embedding_dim, max_pad=max_pad, dense_dim=dense_dim)\n",
        "        self.max_pad = max_pad\n",
        "        self.batch_size = batch_size\n",
        "        self.dense_dim = dense_dim\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, encoder_output, caption):\n",
        "        decoder_h = tf.zeros_like(encoder_output[:,0])\n",
        "        output_array = tf.TensorArray(tf.float32, size=self.max_pad)\n",
        "        for timestep in range(self.max_pad):\n",
        "            output, decoder_h, _ = self.onestepdecoder(caption[:,timestep:timestep+1], encoder_output, decoder_h)\n",
        "            output_array = output_array.write(timestep, output)\n",
        "        output_array = tf.transpose(output_array.stack(), [1, 0, 2])\n",
        "        return output_array\n",
        "\n",
        "# Model Creation and Prediction Functions\n",
        "def create_model():\n",
        "    input_size = (224,224)\n",
        "    tokenizer = joblib.load('tokenizer.pkl')\n",
        "    max_pad = 29\n",
        "    batch_size = 100\n",
        "    vocab_size = len(tokenizer.word_index)\n",
        "    embedding_dim = 300\n",
        "    dense_dim = 512\n",
        "    dropout_rate = 0.2\n",
        "\n",
        "    tf.keras.backend.clear_session()\n",
        "    image1 = Input(shape=input_size + (3,))\n",
        "    image2 = Input(shape=input_size + (3,))\n",
        "    caption = Input(shape=(max_pad,))\n",
        "\n",
        "    encoder_output = encoder(image1, image2, dense_dim, dropout_rate)\n",
        "    output = Decoder(max_pad, embedding_dim, dense_dim, batch_size, vocab_size)(encoder_output, caption)\n",
        "    model = tf.keras.Model(inputs=[image1, image2, caption], outputs=output)\n",
        "    model.load_weights('Encoder_Decoder_global_attention.h5')\n",
        "    return model, tokenizer\n",
        "\n",
        "def greedy_search_predict(image1, image2, model, tokenizer, input_size=(224,224)):\n",
        "    image1 = tf.expand_dims(cv2.resize(image1, input_size, interpolation=cv2.INTER_NEAREST), axis=0)\n",
        "    image2 = tf.expand_dims(cv2.resize(image2, input_size, interpolation=cv2.INTER_NEAREST), axis=0)\n",
        "    image1 = model.get_layer('image_encoder')(image1)\n",
        "    image2 = model.get_layer('image_encoder')(image2)\n",
        "    image1 = model.get_layer('bkdense')(image1)\n",
        "    image2 = model.get_layer('bkdense')(image2)\n",
        "    concat = model.get_layer('concatenate')([image1, image2])\n",
        "    enc_op = model.get_layer('encoder_batch_norm')(concat)\n",
        "    enc_op = model.get_layer('encoder_dropout')(enc_op)\n",
        "\n",
        "    decoder_h = tf.zeros_like(enc_op[:,0])\n",
        "    a = []\n",
        "    max_pad = 29\n",
        "    for i in range(max_pad):\n",
        "        if i == 0:\n",
        "            caption = np.array(tokenizer.texts_to_sequences(['<cls>']))\n",
        "        output, decoder_h, _ = model.get_layer('decoder').onestepdecoder(caption, enc_op, decoder_h)\n",
        "        max_prob = tf.argmax(output, axis=-1)\n",
        "        caption = np.array([max_prob])\n",
        "        if max_prob == np.squeeze(tokenizer.texts_to_sequences(['<end>'])):\n",
        "            break\n",
        "        else:\n",
        "            a.append(tf.squeeze(max_prob).numpy())\n",
        "    return tokenizer.sequences_to_texts([a])[0]\n",
        "\n",
        "def get_bleu(reference, prediction):\n",
        "    reference = [reference.split()]\n",
        "    prediction = prediction.split()\n",
        "    bleu1 = sentence_bleu(reference, prediction, weights=(1,0,0,0))\n",
        "    bleu2 = sentence_bleu(reference, prediction, weights=(0.5,0.5,0,0))\n",
        "    bleu3 = sentence_bleu(reference, prediction, weights=(0.33,0.33,0.33,0))\n",
        "    bleu4 = sentence_bleu(reference, prediction, weights=(0.25,0.25,0.25,0.25))\n",
        "    return bleu1, bleu2, bleu3, bleu4\n",
        "\n",
        "# Utility Functions\n",
        "def predict1(image1, image2=None, model_tokenizer=None):\n",
        "    if image2 is None:\n",
        "        image2 = image1\n",
        "    if model_tokenizer is None:\n",
        "        model, tokenizer = create_model()\n",
        "    else:\n",
        "        model, tokenizer = model_tokenizer\n",
        "    return greedy_search_predict(image1, image2, model, tokenizer)\n",
        "\n",
        "def predict2(true_caption, image1, image2=None, model_tokenizer=None):\n",
        "    if image2 is None:\n",
        "        image2 = image1\n",
        "    if model_tokenizer is None:\n",
        "        model, tokenizer = create_model()\n",
        "    else:\n",
        "        model, tokenizer = model_tokenizer\n",
        "    predicted_caption = greedy_search_predict(image1, image2, model, tokenizer)\n",
        "    scores = get_bleu(true_caption, predicted_caption)\n",
        "    return pd.DataFrame([scores], columns=['bleu1','bleu2','bleu3','bleu4'])\n",
        "\n",
        "def function1(image1_list, image2_list, model_tokenizer=None):\n",
        "    if model_tokenizer is None:\n",
        "        model_tokenizer = list(create_model())\n",
        "    predicted_captions = []\n",
        "    for i1, i2 in zip(image1_list, image2_list):\n",
        "        img1 = cv2.imread(i1, cv2.IMREAD_UNCHANGED)\n",
        "        img2 = cv2.imread(i2, cv2.IMREAD_UNCHANGED)\n",
        "        if img1 is not None and img2 is not None:\n",
        "            img1 = img1 / 255.0\n",
        "            img2 = img2 / 255.0\n",
        "            caption = predict1(img1, img2, model_tokenizer)\n",
        "            predicted_captions.append(caption)\n",
        "        else:\n",
        "            print(f\"Error loading images: {i1}, {i2}\")\n",
        "            predicted_captions.append(\"\")\n",
        "    return predicted_captions\n",
        "\n",
        "def function2(true_captions, image1_list, image2_list):\n",
        "    model_tokenizer = list(create_model())\n",
        "    predicted = pd.DataFrame(columns=['bleu1','bleu2','bleu3','bleu4'])\n",
        "    for c, i1, i2 in zip(true_captions, image1_list, image2_list):\n",
        "        img1 = cv2.imread(i1, cv2.IMREAD_UNCHANGED)\n",
        "        img2 = cv2.imread(i2, cv2.IMREAD_UNCHANGED)\n",
        "        if img1 is not None and img2 is not None:\n",
        "            img1 = img1 / 255.0\n",
        "            img2 = img2 / 255.0\n",
        "            caption = predict2(c, img1, img2, model_tokenizer)\n",
        "            predicted = pd.concat([predicted, caption], ignore_index=True)\n",
        "        else:\n",
        "            print(f\"Error loading images: {i1}, {i2}\")\n",
        "    return predicted\n",
        "\n",
        "# Main Execution\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Loading model and tokenizer...\")\n",
        "    model, tokenizer = create_model()\n",
        "    model_tokenizer = [model, tokenizer]\n",
        "\n",
        "    image1_path = 'image1.png'\n",
        "    image2_path = 'image2.png'\n",
        "\n",
        "    image1 = cv2.imread(image1_path, cv2.IMREAD_UNCHANGED)\n",
        "    image2 = cv2.imread(image2_path, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "    if image1 is None or image2 is None:\n",
        "        print(\"Error: One or both images not found. Check paths.\")\n",
        "    else:\n",
        "        image1 = image1 / 255.0\n",
        "        image2 = image2 / 255.0\n",
        "\n",
        "        print(\"Generating caption for the pair of images...\")\n",
        "        caption = predict1(image1, image2, model_tokenizer)\n",
        "        print(f\"Generated Caption: {caption}\")\n",
        "\n",
        "        image1_list = [image1_path, 'image3.png']\n",
        "        image2_list = [image2_path, 'image4.png']\n",
        "        print(\"\\nGenerating captions for a list of image pairs...\")\n",
        "        captions = function1(image1_list, image2_list, model_tokenizer)\n",
        "        for i, cap in enumerate(captions):\n",
        "            print(f\"Pair {i+1}: {cap}\")\n",
        "\n",
        "        true_captions = [\"no acute cardiopulmonary findings\", \"probably scarring in the left upper lobes\"]\n",
        "        print(\"\\nComputing BLEU scores for a list of image pairs...\")\n",
        "        bleu_scores = function2(true_captions, image1_list, image2_list)\n",
        "        print(bleu_scores)"
      ]
    }
  ]
}
